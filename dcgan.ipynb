{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c378ec",
   "metadata": {},
   "source": [
    "# Implementing the DCGAN in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6538c68",
   "metadata": {},
   "source": [
    "The Generator is trying to generate images mimicking a given input dataset. \n",
    "While the Discriminator's job is to judge if the image you generated can be grouped with the input dataset or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce84b99",
   "metadata": {},
   "source": [
    "##### Let's create a Generator classs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sigmoid\n",
    "from torch import flatten\n",
    "from torch import nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, inputDim=100, outputChannels=1):\n",
    "        super(Generator, self).__init__()\n",
    "        # first set of CONVT => RELU => BN\n",
    "        self.ct1 = ConvTranspose2d(in_channels=inputDim,\n",
    "            out_channels=128, kernel_size=4, stride=2, padding=0,\n",
    "            bias=False)\n",
    "        self.relu1 = ReLU()\n",
    "        self.batchNorm1 = BatchNorm2d(128)\n",
    "        # second set of CONVT => RELU => BN\n",
    "        self.ct2 = ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                    kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.relu2 = ReLU()\n",
    "        self.batchNorm2 = BatchNorm2d(64)\n",
    "        # last set of CONVT => RELU => BN\n",
    "        self.ct3 = ConvTranspose2d(in_channels=64, out_channels=32,\n",
    "                    kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.relu3 = ReLU()\n",
    "        self.batchNorm3 = BatchNorm2d(32)\n",
    "        # apply another upsample and transposed convolution, but\n",
    "        # this time output the TANH activation\n",
    "        self.ct4 = ConvTranspose2d(in_channels=32,\n",
    "            out_channels=outputChannels, kernel_size=4, stride=2,\n",
    "            padding=1, bias=False)\n",
    "        self.tanh = Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONVT => RELU => BN\n",
    "        # layers\n",
    "        x = self.ct1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batchNorm1(x)\n",
    "        # pass the output from previous layer through our second\n",
    "        # CONVT => RELU => BN layer set\n",
    "        x = self.ct2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchNorm2(x)\n",
    "        # pass the output from previous layer through our last set\n",
    "        # of CONVT => RELU => BN layers\n",
    "        x = self.ct3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.batchNorm3(x)\n",
    "        # pass the output from previous layer through CONVT2D => TANH\n",
    "        # layers to get our output\n",
    "        x = self.ct4(x)\n",
    "        output = self.tanh(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2eb0d7",
   "metadata": {},
   "source": [
    "##### Below is the Discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self, depth, alpha=0.2):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\t# first set of CONV => RELU layers\n",
    "\t\tself.conv1 = Conv2d(in_channels=depth, out_channels=32,\n",
    "\t\t\t\tkernel_size=4, stride=2, padding=1)\n",
    "\t\tself.leakyRelu1 = LeakyReLU(alpha, inplace=True)\n",
    "\t\t# second set of CONV => RELU layers\n",
    "\t\tself.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=4,\n",
    "\t\t\t\tstride=2, padding=1)\n",
    "\t\tself.leakyRelu2 = LeakyReLU(alpha, inplace=True)\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=3136, out_features=512)\n",
    "\t\tself.leakyRelu3 = LeakyReLU(alpha, inplace=True)\n",
    "\t\t# sigmoid layer outputting a single value\n",
    "\t\tself.fc2 = Linear(in_features=512, out_features=1)\n",
    "\t\tself.sigmoid = Sigmoid()\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through first set of CONV => RELU layers\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.leakyRelu1(x)\n",
    "\t\t# pass the output from the previous layer through our second\n",
    "\t\t# set of CONV => RELU layers\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.leakyRelu2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our first (and only) set of FC => RELU layers\n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.leakyRelu3(x)\n",
    "\t\t# pass the output from the previous layer through our sigmoid\n",
    "\t\t# layer outputting a single value\n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.sigmoid(x)\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f791d",
   "metadata": {},
   "source": [
    "Training The DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from sklearn.utils import shuffle\n",
    "from imutils import build_montages\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# custom weights initialization called on generator and discriminator\n",
    "def weights_init(model):\n",
    "\tclassname = model.__class__.__name__\n",
    "\t# check if the classname contains the word \"conv\"\n",
    "\tif classname.find(\"Conv\") != -1:\n",
    "\t\t# intialize the weights from normal distribution\n",
    "\t\tnn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "\t# otherwise, check if the name contains the word \"BatcnNorm\"\n",
    "\telif classname.find(\"BatchNorm\") != -1:\n",
    "\t\t# intialize the weights from normal distribution and set the\n",
    "\t\t# bias to 0\n",
    "\t\tnn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "\t\tnn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d062c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:14<00:00, 698371.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 252140.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1571698.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1751772.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataTransforms = transforms.Compose([\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.5), (0.5))]\n",
    ")\n",
    "\n",
    "# load the MNIST dataset and stack the training and testing data\n",
    "# points so we have additional training data\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "trainData = MNIST(root=\"data\", train=True, download=True,\n",
    "\ttransform=dataTransforms)\n",
    "testData = MNIST(root=\"data\", train=False, download=True,\n",
    "\ttransform=dataTransforms)\n",
    "data = torch.utils.data.ConcatDataset((trainData, testData))\n",
    "\n",
    "dataloader = DataLoader(data, shuffle=True,\n",
    "\tbatch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaddd952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3be565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building generator...\n",
      "[INFO] building discriminator...\n"
     ]
    }
   ],
   "source": [
    "stepsPerEpoch = len(dataloader.dataset) // BATCH_SIZE\n",
    "\n",
    "print(\"[INFO] building generator...\")\n",
    "gen = Generator(inputDim=100, outputChannels=1)\n",
    "gen.apply(weights_init)\n",
    "gen.to(DEVICE)\n",
    "\n",
    "print(\"[INFO] building discriminator...\")\n",
    "disc = Discriminator(depth=1)\n",
    "disc.apply(weights_init)\n",
    "disc.to(DEVICE)\n",
    "\n",
    "# initialize optimizer for both generator and discriminator\n",
    "genOpt = Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
    "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
    "discOpt = Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
    "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
    "\n",
    "criterion = BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6057a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting training...\n",
      "[INFO] starting epoch 1 of 20...\n",
      "[INFO] Generator Loss: 4.1125, Discriminator Loss: 0.5142\n",
      "[INFO] starting epoch 2 of 20...\n",
      "[INFO] Generator Loss: 1.0148, Discriminator Loss: 1.1440\n",
      "[INFO] starting epoch 3 of 20...\n",
      "[INFO] Generator Loss: 0.8686, Discriminator Loss: 1.2543\n",
      "[INFO] starting epoch 4 of 20...\n",
      "[INFO] Generator Loss: 0.8309, Discriminator Loss: 1.2938\n",
      "[INFO] starting epoch 5 of 20...\n",
      "[INFO] Generator Loss: 0.8241, Discriminator Loss: 1.3051\n",
      "[INFO] starting epoch 6 of 20...\n",
      "[INFO] Generator Loss: 0.8059, Discriminator Loss: 1.3045\n",
      "[INFO] starting epoch 7 of 20...\n",
      "[INFO] Generator Loss: 0.8055, Discriminator Loss: 1.3038\n",
      "[INFO] starting epoch 8 of 20...\n",
      "[INFO] Generator Loss: 0.8181, Discriminator Loss: 1.3003\n",
      "[INFO] starting epoch 9 of 20...\n",
      "[INFO] Generator Loss: 0.8291, Discriminator Loss: 1.2916\n",
      "[INFO] starting epoch 10 of 20...\n",
      "[INFO] Generator Loss: 0.8447, Discriminator Loss: 1.2856\n",
      "[INFO] starting epoch 11 of 20...\n",
      "[INFO] Generator Loss: 0.8489, Discriminator Loss: 1.2769\n",
      "[INFO] starting epoch 12 of 20...\n",
      "[INFO] Generator Loss: 0.8645, Discriminator Loss: 1.2685\n",
      "[INFO] starting epoch 13 of 20...\n",
      "[INFO] Generator Loss: 0.8788, Discriminator Loss: 1.2607\n",
      "[INFO] starting epoch 14 of 20...\n",
      "[INFO] Generator Loss: 0.8933, Discriminator Loss: 1.2450\n",
      "[INFO] starting epoch 15 of 20...\n",
      "[INFO] Generator Loss: 0.9077, Discriminator Loss: 1.2390\n",
      "[INFO] starting epoch 16 of 20...\n",
      "[INFO] Generator Loss: 0.9239, Discriminator Loss: 1.2259\n",
      "[INFO] starting epoch 17 of 20...\n",
      "[INFO] Generator Loss: 0.9492, Discriminator Loss: 1.2151\n",
      "[INFO] starting epoch 18 of 20...\n",
      "[INFO] Generator Loss: 0.9646, Discriminator Loss: 1.2013\n",
      "[INFO] starting epoch 19 of 20...\n",
      "[INFO] Generator Loss: 0.9826, Discriminator Loss: 1.1876\n",
      "[INFO] starting epoch 20 of 20...\n",
      "[INFO] Generator Loss: 1.0049, Discriminator Loss: 1.1766\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] starting training...\")\n",
    "benchmarkNoise = torch.randn(256, 100, 1, 1, device=DEVICE)\n",
    "\n",
    "realLabel = 1\n",
    "fakeLabel = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\tprint(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
    "\t\tNUM_EPOCHS))\n",
    "\t\n",
    "\tepochLossG = 0\n",
    "\tepochLossD = 0\n",
    "\tfor x in dataloader:\n",
    "\t\tdisc.zero_grad()\n",
    "\t\t\n",
    "\t\timages = x[0]\n",
    "\t\timages = images.to(DEVICE)\n",
    "\t\t\n",
    "\t\tbs =  images.size(0)\n",
    "\t\tlabels = torch.full((bs,), realLabel, dtype=torch.float,\n",
    "\t\t\tdevice=DEVICE)\n",
    "\t\t\n",
    "\t\toutput = disc(images).view(-1)\n",
    "\t\t# calculate the loss on all-real batch\n",
    "\t\terrorReal = criterion(output, labels)\n",
    "\t\terrorReal.backward()\n",
    "\n",
    "\t\tnoise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "\t\t# generate a fake image batch using the generator\n",
    "\t\tfake = gen(noise)\n",
    "\t\tlabels.fill_(fakeLabel)\n",
    "\n",
    "\t\t# perform a forward pass through discriminator using fake\n",
    "\t\t# batch data\n",
    "\t\toutput = disc(fake.detach()).view(-1)\n",
    "\t\terrorFake = criterion(output, labels)\n",
    "\t\terrorFake.backward()\n",
    "\t\terrorD = errorReal + errorFake\n",
    "\t\tdiscOpt.step()\n",
    "\n",
    "\t\tgen.zero_grad()\n",
    "\t\t# update the labels as fake labels are real for the generator\n",
    "\t\t# and perform a forward pass  of fake data batch through the\n",
    "\t\t# discriminator\n",
    "\t\tlabels.fill_(realLabel)\n",
    "\t\toutput = disc(fake).view(-1)\n",
    "\t\t# calculate generator's loss based on output from\n",
    "\t\t# discriminator and calculate gradients for generator\n",
    "\t\terrorG = criterion(output, labels)\n",
    "\t\terrorG.backward()\n",
    "\t\t# update the generator\n",
    "\t\tgenOpt.step()\n",
    "\t\t# add the current iteration loss of discriminator and\n",
    "\t\t# generator\n",
    "\t\tepochLossD += errorD\n",
    "\t\tepochLossG += errorG\n",
    "\n",
    "\tprint(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(\n",
    "\t\tepochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "\t\n",
    "\tif (epoch + 1) % 2 == 0:\n",
    "\t\t# set the generator in evaluation phase, make predictions on\n",
    "\t\t# the benchmark noise, scale it back to the range [0, 255],\n",
    "\t\t# and generate the montage\n",
    "\t\tgen.eval()\n",
    "\t\timages = gen(benchmarkNoise)\n",
    "\t\timages = images.detach().cpu().numpy().transpose((0, 2, 3, 1))\n",
    "\t\timages = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
    "\t\timages = np.repeat(images, 3, axis=-1)\n",
    "\t\tvis = build_montages(images, (28, 28), (16, 16))[0]\n",
    "\t\t\n",
    "\t\t# save output\n",
    "\t\tp = os.path.join('output', \"epoch_{}.png\".format(\n",
    "\t\t\tstr(epoch + 1).zfill(4)))\n",
    "\t\tcv2.imwrite(p, vis)\n",
    "\t\tgen.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79320421",
   "metadata": {},
   "source": [
    "Let's see an example of what ot generates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e1ba51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "gen.eval()\n",
    "\n",
    "noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "img = gen(noise).detach().cpu()\n",
    "\n",
    "img = img[0][0]\n",
    "img = (img + 1.0) / 2.0\n",
    "img = np.clip(img, 0, 1)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Generated Image\")\n",
    "plt.show()\n",
    "print(img.shape)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
